{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ac526d-81a4-4ce9-9082-121a8202f5de",
   "metadata": {},
   "source": [
    "# Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d943dd-1f78-49ba-8b57-21976aa1cc2f",
   "metadata": {},
   "source": [
    "## Objective: \n",
    "Create a pipeline to transform the log data into a dataframe we can use for predictive modelling.\n",
    "\n",
    "## Table format: Features\n",
    "\n",
    "### Input Features\n",
    "\n",
    "- $ n $: Number of elements (e.g., 16, 31).\n",
    "- $ k $: Number of partitions (e.g., 5, 4).\n",
    "- Total sum: $ \\sum S $ (requires input numbers).\n",
    "- Variance: $ \\text{var}(S) $.\n",
    "- Skewness: Distribution shape\n",
    "- Max/min number.\n",
    "- Average subset sum: $ \\text{total sum} / k $.\n",
    "\n",
    "### Solver Features (First $ k $ Logs at stackDepth=3):\n",
    "\n",
    "**For each log (up to $ k $):**\n",
    "\n",
    "- evts: Events at stackDepth=3.\n",
    "- expandEvts: Expansions.\n",
    "- pruneBacktrackEvts: Pruning backtracks.\n",
    "- backtrackEvts: Non-pruning backtracks.\n",
    "- strengthenEvts: Constraint tightenings.\n",
    "- maxStackDepth: Maximum depth reached.\n",
    "- Subset sums: Sum of numbers assigned to each subset based on path (requires input numbers).\n",
    "- Subset sum variance: Variance of subset sums.\n",
    "- Aggregated: Average or max evts, expandEvts, pruneBacktrackEvts across the $ k $ logs.\n",
    "- num_stackdepth3_logs: Number of stackDepth=3 logs (proxy for search difficulty).\n",
    "\n",
    "### Termination/Timeout Features\n",
    "- expandEvts (target variable).\n",
    "- Censored flag: 1 for timeouts, 0 for completions.\n",
    "- Objective value: maxsum - minsum (if available, e.g., 2 for $ n=10, k=3 $)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4147a1e7-32ff-4a08-8344-b1b56a408eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ab28a-c06c-4ddc-b433-f0edbfdd13c6",
   "metadata": {},
   "source": [
    "# 1. Create a dataframe with solver features\n",
    "The solver features are as listed above. The index will be the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59262034-d4ef-465c-b1dc-23d5495289eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 690 instances\n",
      "DataFrame shape: (690, 41)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_ml_features(jsonl_path):\n",
    "    \"\"\"\n",
    "    Extract ML features from the ml_features.jsonl file.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to the ml_features.jsonl file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the extracted features\n",
    "    \"\"\"\n",
    "    # List to store data for each instance\n",
    "    data_list = []\n",
    "    \n",
    "    # Open and process the JSONL file\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Parse the JSON line\n",
    "                line_data = json.loads(line.strip())\n",
    "                \n",
    "                # Each line contains a single key (filename) with an array of log entries\n",
    "                for filename, logs in line_data.items():\n",
    "                    if not logs:  # Skip if no logs\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract n and k from filename using regex\n",
    "                    match = re.search(r'n(\\d+)k(\\d+)', filename)\n",
    "                    if match:\n",
    "                        k = int(match.group(2))  # Number of partitions\n",
    "                    else:\n",
    "                        # If pattern doesn't match, try to infer from the logs\n",
    "                        k = max(3, min(5, len(logs)))\n",
    "                    \n",
    "                    # Initialize feature dictionary\n",
    "                    features = {\n",
    "                        'filename': filename,\n",
    "                        'num_stackdepth3_logs': 0\n",
    "                    }\n",
    "                    \n",
    "                    # Extract individual log features (up to k logs)\n",
    "                    for i in range(min(k, len(logs))):\n",
    "                        log = logs[i]\n",
    "                        \n",
    "                        if log.get('stackDepth', 0) == 3:\n",
    "                            features['num_stackdepth3_logs'] += 1\n",
    "                            \n",
    "                        # Extract all numeric features from this log\n",
    "                        for field in ['evts', 'expandEvts', 'pruneBacktrackEvts', \n",
    "                                     'backtrackEvts', 'strengthenEvts', 'maxStackDepth']:\n",
    "                            if field in log:\n",
    "                                features[f'{field}_{i+1}'] = log[field]\n",
    "                    \n",
    "                    # Find the termination or timeout event (should be the last log)\n",
    "                    last_log = logs[-1]\n",
    "                    last_event = last_log.get('event', '')\n",
    "                    \n",
    "                    # Check for either TIMEOUT or TERMINATE events\n",
    "                    is_timeout = last_event == 'TIMEOUT'\n",
    "                    is_terminated = last_event == 'TERMINATE'\n",
    "                    \n",
    "                    # Add target variables\n",
    "                    features['censored'] = 1 if is_timeout else 0\n",
    "                    features['final_expandEvts'] = last_log.get('expandEvts', 0)\n",
    "                    features['final_maxStackDepth'] = last_log.get('maxStackDepth', 0)\n",
    "                    \n",
    "                    # Add specific event information if available\n",
    "                    if is_timeout and 'timeoutAt' in last_log:\n",
    "                        features['stop_iter'] = last_log['timeoutAt']\n",
    "                    elif is_terminated and 'terminateAt' in last_log:\n",
    "                        features['stop_iter'] = last_log['terminateAt']\n",
    "                    else:\n",
    "                        features['stop_iter'] = last_log.get('iter', 0)\n",
    "                    \n",
    "                    # Calculate aggregated features\n",
    "                    for field in ['evts', 'expandEvts', 'pruneBacktrackEvts']:\n",
    "                        values = [log.get(field, 0) for log in logs[:k] if field in log]\n",
    "                        if values:\n",
    "                            features[f'avg_{field}'] = sum(values) / len(values)\n",
    "                            features[f'max_{field}'] = max(values)\n",
    "                    \n",
    "                    # Add to data list\n",
    "                    data_list.append(features)\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON line: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.set_index(\"filename\")\n",
    "    \n",
    "    # For demonstration, print the shape and first few rows\n",
    "    print(f\"Extracted features for {len(df)} instances\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "solver_features_df = extract_ml_features(\"ml_features.jsonl\")\n",
    "# df.to_csv(\"ml_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d33b8f-50c2-493a-be73-dc5239756cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_stackdepth3_logs</th>\n",
       "      <th>evts_1</th>\n",
       "      <th>expandEvts_1</th>\n",
       "      <th>pruneBacktrackEvts_1</th>\n",
       "      <th>backtrackEvts_1</th>\n",
       "      <th>strengthenEvts_1</th>\n",
       "      <th>maxStackDepth_1</th>\n",
       "      <th>evts_2</th>\n",
       "      <th>expandEvts_2</th>\n",
       "      <th>pruneBacktrackEvts_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pruneBacktrackEvts_4</th>\n",
       "      <th>backtrackEvts_4</th>\n",
       "      <th>strengthenEvts_4</th>\n",
       "      <th>maxStackDepth_4</th>\n",
       "      <th>evts_5</th>\n",
       "      <th>expandEvts_5</th>\n",
       "      <th>pruneBacktrackEvts_5</th>\n",
       "      <th>backtrackEvts_5</th>\n",
       "      <th>strengthenEvts_5</th>\n",
       "      <th>maxStackDepth_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              num_stackdepth3_logs  evts_1  expandEvts_1  \\\n",
       "filename                                                   \n",
       "n10k3_v1.txt                     3       4             4   \n",
       "n10k3_v2.txt                     3       4             4   \n",
       "n10k3_v3.txt                     3       4             4   \n",
       "n10k3_v4.txt                     3       4             4   \n",
       "n10k3_v5.txt                     3       4             4   \n",
       "...                            ...     ...           ...   \n",
       "n9k5_v1.txt                      2       4             4   \n",
       "n9k5_v2.txt                      5       4             4   \n",
       "n9k5_v3.txt                      2       4             4   \n",
       "n9k5_v4.txt                      2       4             4   \n",
       "n9k5_v5.txt                      5       4             4   \n",
       "\n",
       "              pruneBacktrackEvts_1  backtrackEvts_1  strengthenEvts_1  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt                     0                0                 0   \n",
       "n10k3_v2.txt                     0                0                 0   \n",
       "n10k3_v3.txt                     0                0                 0   \n",
       "n10k3_v4.txt                     0                0                 0   \n",
       "n10k3_v5.txt                     0                0                 0   \n",
       "...                            ...              ...               ...   \n",
       "n9k5_v1.txt                      0                0                 0   \n",
       "n9k5_v2.txt                      0                0                 0   \n",
       "n9k5_v3.txt                      0                0                 0   \n",
       "n9k5_v4.txt                      0                0                 0   \n",
       "n9k5_v5.txt                      0                0                 0   \n",
       "\n",
       "              maxStackDepth_1  evts_2  expandEvts_2  pruneBacktrackEvts_2  \\\n",
       "filename                                                                    \n",
       "n10k3_v1.txt                3      60            30                    25   \n",
       "n10k3_v2.txt                3      59            31                    25   \n",
       "n10k3_v3.txt                3      66            34                    27   \n",
       "n10k3_v4.txt                3     106            54                    47   \n",
       "n10k3_v5.txt                3      21            11                     8   \n",
       "...                       ...     ...           ...                   ...   \n",
       "n9k5_v1.txt                 3      19            10                     7   \n",
       "n9k5_v2.txt                 3      27            15                    10   \n",
       "n9k5_v3.txt                 3      19            10                     7   \n",
       "n9k5_v4.txt                 3      19            10                     7   \n",
       "n9k5_v5.txt                 3      23            13                     8   \n",
       "\n",
       "              ...  pruneBacktrackEvts_4  backtrackEvts_4  strengthenEvts_4  \\\n",
       "filename      ...                                                            \n",
       "n10k3_v1.txt  ...                   NaN              NaN               NaN   \n",
       "n10k3_v2.txt  ...                   NaN              NaN               NaN   \n",
       "n10k3_v3.txt  ...                   NaN              NaN               NaN   \n",
       "n10k3_v4.txt  ...                   NaN              NaN               NaN   \n",
       "n10k3_v5.txt  ...                   NaN              NaN               NaN   \n",
       "...           ...                   ...              ...               ...   \n",
       "n9k5_v1.txt   ...                   NaN              NaN               NaN   \n",
       "n9k5_v2.txt   ...                  29.0              1.0               1.0   \n",
       "n9k5_v3.txt   ...                   NaN              NaN               NaN   \n",
       "n9k5_v4.txt   ...                   NaN              NaN               NaN   \n",
       "n9k5_v5.txt   ...                  19.0              1.0               1.0   \n",
       "\n",
       "              maxStackDepth_4  evts_5  expandEvts_5  pruneBacktrackEvts_5  \\\n",
       "filename                                                                    \n",
       "n10k3_v1.txt              NaN     NaN           NaN                   NaN   \n",
       "n10k3_v2.txt              NaN     NaN           NaN                   NaN   \n",
       "n10k3_v3.txt              NaN     NaN           NaN                   NaN   \n",
       "n10k3_v4.txt              NaN     NaN           NaN                   NaN   \n",
       "n10k3_v5.txt              NaN     NaN           NaN                   NaN   \n",
       "...                       ...     ...           ...                   ...   \n",
       "n9k5_v1.txt               NaN     NaN           NaN                   NaN   \n",
       "n9k5_v2.txt              10.0    65.0          34.0                  29.0   \n",
       "n9k5_v3.txt               NaN     NaN           NaN                   NaN   \n",
       "n9k5_v4.txt               NaN     NaN           NaN                   NaN   \n",
       "n9k5_v5.txt              10.0    45.0          24.0                  19.0   \n",
       "\n",
       "              backtrackEvts_5  strengthenEvts_5  maxStackDepth_5  \n",
       "filename                                                          \n",
       "n10k3_v1.txt              NaN               NaN              NaN  \n",
       "n10k3_v2.txt              NaN               NaN              NaN  \n",
       "n10k3_v3.txt              NaN               NaN              NaN  \n",
       "n10k3_v4.txt              NaN               NaN              NaN  \n",
       "n10k3_v5.txt              NaN               NaN              NaN  \n",
       "...                       ...               ...              ...  \n",
       "n9k5_v1.txt               NaN               NaN              NaN  \n",
       "n9k5_v2.txt               1.0               1.0             10.0  \n",
       "n9k5_v3.txt               NaN               NaN              NaN  \n",
       "n9k5_v4.txt               NaN               NaN              NaN  \n",
       "n9k5_v5.txt               1.0               1.0             10.0  \n",
       "\n",
       "[690 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a375aa-262a-49c2-a4b3-8e57d0a0b8bd",
   "metadata": {},
   "source": [
    "## 2. Create a Dataframe with input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da3d811-5a73-49cd-8ae3-735cc02397d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 690 instance files\n",
      "Missing 0 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>total_sum</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>max_num</th>\n",
       "      <th>min_num</th>\n",
       "      <th>avg_subset_sum</th>\n",
       "      <th>max_to_avg_ratio</th>\n",
       "      <th>range_to_avg_ratio</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1060.810000</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>0.585799</td>\n",
       "      <td>0.579882</td>\n",
       "      <td>0.642408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>683.040000</td>\n",
       "      <td>-0.125352</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.333333</td>\n",
       "      <td>0.550403</td>\n",
       "      <td>0.538306</td>\n",
       "      <td>0.526916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>777.560000</td>\n",
       "      <td>-0.007893</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.666667</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.544624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>658.250000</td>\n",
       "      <td>0.199096</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>0.558416</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.508047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1497.490000</td>\n",
       "      <td>-0.182731</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166.333333</td>\n",
       "      <td>0.553106</td>\n",
       "      <td>0.535070</td>\n",
       "      <td>0.775499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1161.654321</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>1.069042</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.683179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>580.024691</td>\n",
       "      <td>-0.392412</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>105.400000</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.702087</td>\n",
       "      <td>0.411297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1034.469136</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>1.046256</td>\n",
       "      <td>0.637596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>938.691358</td>\n",
       "      <td>0.280482</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>1.187990</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>0.719955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>940.543210</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>1.013363</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.614732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 n    k  total_sum     variance  skewness  max_num  min_num  \\\n",
       "filename                                                                      \n",
       "n10k3_v1.txt  10.0  3.0      507.0  1060.810000 -0.047343     99.0      1.0   \n",
       "n10k3_v2.txt  10.0  3.0      496.0   683.040000 -0.125352     91.0      2.0   \n",
       "n10k3_v3.txt  10.0  3.0      512.0   777.560000 -0.007893     91.0      8.0   \n",
       "n10k3_v4.txt  10.0  3.0      505.0   658.250000  0.199096     94.0      9.0   \n",
       "n10k3_v5.txt  10.0  3.0      499.0  1497.490000 -0.182731     92.0      3.0   \n",
       "...            ...  ...        ...          ...       ...      ...      ...   \n",
       "n9k5_v1.txt    9.0  5.0      449.0  1161.654321  0.116110     96.0      8.0   \n",
       "n9k5_v2.txt    9.0  5.0      527.0   580.024691 -0.392412     86.0     12.0   \n",
       "n9k5_v3.txt    9.0  5.0      454.0  1034.469136  0.112580     98.0      3.0   \n",
       "n9k5_v4.txt    9.0  5.0      383.0   938.691358  0.280482     91.0      3.0   \n",
       "n9k5_v5.txt    9.0  5.0      449.0   940.543210 -0.003903     91.0      5.0   \n",
       "\n",
       "              avg_subset_sum  max_to_avg_ratio  range_to_avg_ratio  \\\n",
       "filename                                                             \n",
       "n10k3_v1.txt      169.000000          0.585799            0.579882   \n",
       "n10k3_v2.txt      165.333333          0.550403            0.538306   \n",
       "n10k3_v3.txt      170.666667          0.533203            0.486328   \n",
       "n10k3_v4.txt      168.333333          0.558416            0.504950   \n",
       "n10k3_v5.txt      166.333333          0.553106            0.535070   \n",
       "...                      ...               ...                 ...   \n",
       "n9k5_v1.txt        89.800000          1.069042            0.979955   \n",
       "n9k5_v2.txt       105.400000          0.815939            0.702087   \n",
       "n9k5_v3.txt        90.800000          1.079295            1.046256   \n",
       "n9k5_v4.txt        76.600000          1.187990            1.148825   \n",
       "n9k5_v5.txt        89.800000          1.013363            0.957684   \n",
       "\n",
       "              coef_of_variation  \n",
       "filename                         \n",
       "n10k3_v1.txt           0.642408  \n",
       "n10k3_v2.txt           0.526916  \n",
       "n10k3_v3.txt           0.544624  \n",
       "n10k3_v4.txt           0.508047  \n",
       "n10k3_v5.txt           0.775499  \n",
       "...                         ...  \n",
       "n9k5_v1.txt            0.683179  \n",
       "n9k5_v2.txt            0.411297  \n",
       "n9k5_v3.txt            0.637596  \n",
       "n9k5_v4.txt            0.719955  \n",
       "n9k5_v5.txt            0.614732  \n",
       "\n",
       "[690 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process_path_features(df, instance_dir):\n",
    "    \"\"\"\n",
    "    Process input features from the original instance files.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with existing features from logs\n",
    "        instance_dir: Directory containing the original instance files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with input features\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame for input features with filename as index\n",
    "    input_features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Track missing files\n",
    "    missing_files = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    # Process each file\n",
    "    for filename in df.index:\n",
    "        file_path = os.path.join(instance_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                missing_files.append(filename)\n",
    "                continue\n",
    "                \n",
    "            # Read the instance file\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Extract data from file\n",
    "            solution = int(lines[0].strip())  # -1 if no solution\n",
    "            k = int(lines[1].strip())         # number of partitions\n",
    "            numbers = [int(line.strip()) for line in lines[2:]]\n",
    "            n = len(numbers)                  # number of elements\n",
    "            \n",
    "            # Calculate basic input features\n",
    "            total_sum = sum(numbers)\n",
    "            variance = np.var(numbers) if n > 1 else 0\n",
    "            skewness = stats.skew(numbers) if n > 2 else 0\n",
    "            max_num = max(numbers) if numbers else 0\n",
    "            min_num = min(numbers) if numbers else 0\n",
    "            avg_subset_sum = total_sum / k if k > 0 else 0\n",
    "            \n",
    "            # Store features\n",
    "            input_features.loc[filename, 'n'] = n\n",
    "            input_features.loc[filename, 'k'] = k\n",
    "            input_features.loc[filename, 'total_sum'] = total_sum\n",
    "            input_features.loc[filename, 'variance'] = variance\n",
    "            input_features.loc[filename, 'skewness'] = skewness\n",
    "            input_features.loc[filename, 'max_num'] = max_num\n",
    "            input_features.loc[filename, 'min_num'] = min_num\n",
    "            input_features.loc[filename, 'avg_subset_sum'] = avg_subset_sum\n",
    "            \n",
    "            # Calculate additional features\n",
    "            \n",
    "            # How close is the maximum number to the average subset sum?\n",
    "            # If max_num > avg_subset_sum, the problem is likely harder\n",
    "            input_features.loc[filename, 'max_to_avg_ratio'] = max_num / avg_subset_sum if avg_subset_sum > 0 else float('inf')\n",
    "            \n",
    "            # Range to average ratio\n",
    "            input_features.loc[filename, 'range_to_avg_ratio'] = (max_num - min_num) / avg_subset_sum if avg_subset_sum > 0 else float('inf')\n",
    "            \n",
    "            # Coefficient of variation (standardized measure of dispersion)\n",
    "            mean = np.mean(numbers)\n",
    "            std_dev = np.std(numbers)\n",
    "            input_features.loc[filename, 'coef_of_variation'] = std_dev / mean if mean > 0 else 0\n",
    "            \n",
    "            processed_files += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            missing_files.append(filename)\n",
    "    \n",
    "    print(f\"Processed {processed_files} instance files\")\n",
    "    print(f\"Missing {len(missing_files)} files\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"First few missing files: {missing_files[:5]}\")\n",
    "    \n",
    "    # Return a new DataFrame with input features\n",
    "    # This keeps the original df unchanged and allows for better merging later\n",
    "    return input_features\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "instance_dir = \"solver/numpart/instances/feature_collected\"\n",
    "input_features_df = process_path_features(solver_features_df, instance_dir)\n",
    "# df = extract_and_analyze_ml_features(\"ml_features.jsonl\", instance_dir)\n",
    "# df.to_csv(\"ml_features_complete.csv\", index=False)\n",
    "\n",
    "input_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25aefbb-ba77-479c-b83e-ea4ed05175f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged features: 690 rows, 52 columns\n"
     ]
    }
   ],
   "source": [
    "def merge_features(solver_features_df, input_features_df):\n",
    "    \"\"\"\n",
    "    Merge solver features with input features.\n",
    "    \n",
    "    Args:\n",
    "        solver_features_df: DataFrame with solver features\n",
    "        input_features_df: DataFrame with input features\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Merged DataFrame\n",
    "    \"\"\"\n",
    "    # Set filename as index for solver features to enable proper joining\n",
    "    # solver_features_df = solver_features_df.set_index('filename')\n",
    "    \n",
    "    # Merge DataFrames on filename index\n",
    "    merged_df = solver_features_df.join(input_features_df, how='inner', lsuffix='_solver', rsuffix='_input')\n",
    "    \n",
    "    # Reset index to make filename a column again\n",
    "    # merged_df = merged_df.reset_index()\n",
    "    \n",
    "    print(f\"Merged features: {len(merged_df)} rows, {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "df = merge_features(solver_features_df, input_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09446521-34c5-4507-9b6c-224c7db80b46",
   "metadata": {},
   "source": [
    "## Extend Dataframe\n",
    "Create another table with the following features:\n",
    "- subset_sum_max,\n",
    "- subset_sum_min,\n",
    "- subset_sum_variance\n",
    "This is applicable to those that didn't timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e69d27-cb74-4100-a50e-741b63de22f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_stackdepth3_logs</th>\n",
       "      <th>evts_1</th>\n",
       "      <th>expandEvts_1</th>\n",
       "      <th>pruneBacktrackEvts_1</th>\n",
       "      <th>backtrackEvts_1</th>\n",
       "      <th>strengthenEvts_1</th>\n",
       "      <th>maxStackDepth_1</th>\n",
       "      <th>evts_2</th>\n",
       "      <th>expandEvts_2</th>\n",
       "      <th>pruneBacktrackEvts_2</th>\n",
       "      <th>...</th>\n",
       "      <th>k</th>\n",
       "      <th>total_sum</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>max_num</th>\n",
       "      <th>min_num</th>\n",
       "      <th>avg_subset_sum</th>\n",
       "      <th>max_to_avg_ratio</th>\n",
       "      <th>range_to_avg_ratio</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1060.810000</td>\n",
       "      <td>-0.047343</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>0.585799</td>\n",
       "      <td>0.579882</td>\n",
       "      <td>0.642408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>683.040000</td>\n",
       "      <td>-0.125352</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.333333</td>\n",
       "      <td>0.550403</td>\n",
       "      <td>0.538306</td>\n",
       "      <td>0.526916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>777.560000</td>\n",
       "      <td>-0.007893</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.666667</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.544624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>658.250000</td>\n",
       "      <td>0.199096</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>0.558416</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.508047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1497.490000</td>\n",
       "      <td>-0.182731</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166.333333</td>\n",
       "      <td>0.553106</td>\n",
       "      <td>0.535070</td>\n",
       "      <td>0.775499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1161.654321</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>1.069042</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.683179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>580.024691</td>\n",
       "      <td>-0.392412</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>105.400000</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.702087</td>\n",
       "      <td>0.411297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1034.469136</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>1.046256</td>\n",
       "      <td>0.637596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>938.691358</td>\n",
       "      <td>0.280482</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>1.187990</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>0.719955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>940.543210</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>1.013363</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.614732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              num_stackdepth3_logs  evts_1  expandEvts_1  \\\n",
       "filename                                                   \n",
       "n10k3_v1.txt                     3       4             4   \n",
       "n10k3_v2.txt                     3       4             4   \n",
       "n10k3_v3.txt                     3       4             4   \n",
       "n10k3_v4.txt                     3       4             4   \n",
       "n10k3_v5.txt                     3       4             4   \n",
       "...                            ...     ...           ...   \n",
       "n9k5_v1.txt                      2       4             4   \n",
       "n9k5_v2.txt                      5       4             4   \n",
       "n9k5_v3.txt                      2       4             4   \n",
       "n9k5_v4.txt                      2       4             4   \n",
       "n9k5_v5.txt                      5       4             4   \n",
       "\n",
       "              pruneBacktrackEvts_1  backtrackEvts_1  strengthenEvts_1  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt                     0                0                 0   \n",
       "n10k3_v2.txt                     0                0                 0   \n",
       "n10k3_v3.txt                     0                0                 0   \n",
       "n10k3_v4.txt                     0                0                 0   \n",
       "n10k3_v5.txt                     0                0                 0   \n",
       "...                            ...              ...               ...   \n",
       "n9k5_v1.txt                      0                0                 0   \n",
       "n9k5_v2.txt                      0                0                 0   \n",
       "n9k5_v3.txt                      0                0                 0   \n",
       "n9k5_v4.txt                      0                0                 0   \n",
       "n9k5_v5.txt                      0                0                 0   \n",
       "\n",
       "              maxStackDepth_1  evts_2  expandEvts_2  pruneBacktrackEvts_2  \\\n",
       "filename                                                                    \n",
       "n10k3_v1.txt                3      60            30                    25   \n",
       "n10k3_v2.txt                3      59            31                    25   \n",
       "n10k3_v3.txt                3      66            34                    27   \n",
       "n10k3_v4.txt                3     106            54                    47   \n",
       "n10k3_v5.txt                3      21            11                     8   \n",
       "...                       ...     ...           ...                   ...   \n",
       "n9k5_v1.txt                 3      19            10                     7   \n",
       "n9k5_v2.txt                 3      27            15                    10   \n",
       "n9k5_v3.txt                 3      19            10                     7   \n",
       "n9k5_v4.txt                 3      19            10                     7   \n",
       "n9k5_v5.txt                 3      23            13                     8   \n",
       "\n",
       "              ...    k  total_sum     variance  skewness  max_num  min_num  \\\n",
       "filename      ...                                                            \n",
       "n10k3_v1.txt  ...  3.0      507.0  1060.810000 -0.047343     99.0      1.0   \n",
       "n10k3_v2.txt  ...  3.0      496.0   683.040000 -0.125352     91.0      2.0   \n",
       "n10k3_v3.txt  ...  3.0      512.0   777.560000 -0.007893     91.0      8.0   \n",
       "n10k3_v4.txt  ...  3.0      505.0   658.250000  0.199096     94.0      9.0   \n",
       "n10k3_v5.txt  ...  3.0      499.0  1497.490000 -0.182731     92.0      3.0   \n",
       "...           ...  ...        ...          ...       ...      ...      ...   \n",
       "n9k5_v1.txt   ...  5.0      449.0  1161.654321  0.116110     96.0      8.0   \n",
       "n9k5_v2.txt   ...  5.0      527.0   580.024691 -0.392412     86.0     12.0   \n",
       "n9k5_v3.txt   ...  5.0      454.0  1034.469136  0.112580     98.0      3.0   \n",
       "n9k5_v4.txt   ...  5.0      383.0   938.691358  0.280482     91.0      3.0   \n",
       "n9k5_v5.txt   ...  5.0      449.0   940.543210 -0.003903     91.0      5.0   \n",
       "\n",
       "              avg_subset_sum  max_to_avg_ratio  range_to_avg_ratio  \\\n",
       "filename                                                             \n",
       "n10k3_v1.txt      169.000000          0.585799            0.579882   \n",
       "n10k3_v2.txt      165.333333          0.550403            0.538306   \n",
       "n10k3_v3.txt      170.666667          0.533203            0.486328   \n",
       "n10k3_v4.txt      168.333333          0.558416            0.504950   \n",
       "n10k3_v5.txt      166.333333          0.553106            0.535070   \n",
       "...                      ...               ...                 ...   \n",
       "n9k5_v1.txt        89.800000          1.069042            0.979955   \n",
       "n9k5_v2.txt       105.400000          0.815939            0.702087   \n",
       "n9k5_v3.txt        90.800000          1.079295            1.046256   \n",
       "n9k5_v4.txt        76.600000          1.187990            1.148825   \n",
       "n9k5_v5.txt        89.800000          1.013363            0.957684   \n",
       "\n",
       "              coef_of_variation  \n",
       "filename                         \n",
       "n10k3_v1.txt           0.642408  \n",
       "n10k3_v2.txt           0.526916  \n",
       "n10k3_v3.txt           0.544624  \n",
       "n10k3_v4.txt           0.508047  \n",
       "n10k3_v5.txt           0.775499  \n",
       "...                         ...  \n",
       "n9k5_v1.txt            0.683179  \n",
       "n9k5_v2.txt            0.411297  \n",
       "n9k5_v3.txt            0.637596  \n",
       "n9k5_v4.txt            0.719955  \n",
       "n9k5_v5.txt            0.614732  \n",
       "\n",
       "[690 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa643480-9a71-41f0-aefc-bcd2bc9f6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_dataframe_with_termination_stats(df, jsonl_path=\"termination_stats.jsonl\"):\n",
    "    \"\"\"\n",
    "    Enrich an existing pandas DataFrame with termination statistics from a JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame to enrich. File names should be in the index.\n",
    "        jsonl_path: Path to the JSONL file containing termination statistics.\n",
    "                   Default is \"termination_stats.jsonl\".\n",
    "    \n",
    "    Returns:\n",
    "        Enriched pandas DataFrame with new columns for subset sum statistics.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    # Check if the input dataframe is valid\n",
    "    if df is None or df.empty:\n",
    "        raise ValueError(\"Input DataFrame is empty or None\")\n",
    "    \n",
    "    # Check if the JSONL file exists\n",
    "    if not os.path.exists(jsonl_path):\n",
    "        raise FileNotFoundError(f\"Termination stats file not found at {jsonl_path}\")\n",
    "    \n",
    "    # Initialize new columns with NaN values\n",
    "    df['subset_sum_max'] = float('nan')\n",
    "    df['subset_sum_min'] = float('nan')\n",
    "    df['subset_sum_variance'] = float('nan')\n",
    "    \n",
    "    # Counter for tracking stats\n",
    "    stats_count = 0\n",
    "    missing_files = []\n",
    "    \n",
    "    # Read the JSONL file line by line and update the dataframe\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Parse JSON line\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Each line has a single key (filename) mapped to stats\n",
    "                for filename, stats in data.items():\n",
    "                    # Check if this filename exists in the dataframe index\n",
    "                    if filename in df.index:\n",
    "                        # Update the dataframe with the statistics\n",
    "                        df.at[filename, 'subset_sum_max'] = stats['subset_sum_max']\n",
    "                        df.at[filename, 'subset_sum_min'] = stats['subset_sum_min']\n",
    "                        df.at[filename, 'subset_sum_variance'] = stats['subset_sum_variance']\n",
    "                        stats_count += 1\n",
    "                    else:\n",
    "                        missing_files.append(filename)\n",
    "            except json.JSONDecodeError:\n",
    "                # Skip invalid JSON lines\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Enriched DataFrame with termination stats for {stats_count} files\")\n",
    "    if missing_files:\n",
    "        print(f\"Warning: {len(missing_files)} files from the JSONL were not found in the DataFrame index\")\n",
    "        if len(missing_files) <= 10:\n",
    "            print(f\"Missing files: {missing_files}\")\n",
    "        else:\n",
    "            print(f\"First 10 missing files: {missing_files[:10]}...\")\n",
    "    \n",
    "    # Report how many rows have NaN values in the new columns\n",
    "    nan_count = df['subset_sum_max'].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Warning: {nan_count} rows in the DataFrame have no termination statistics\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df = enrich_dataframe_with_termination_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b10853d-b10e-494b-ae6b-4f239bdd8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_stackdepth3_logs', 'evts_1', 'expandEvts_1',\n",
       "       'pruneBacktrackEvts_1', 'backtrackEvts_1', 'strengthenEvts_1',\n",
       "       'maxStackDepth_1', 'evts_2', 'expandEvts_2', 'pruneBacktrackEvts_2',\n",
       "       'backtrackEvts_2', 'strengthenEvts_2', 'maxStackDepth_2', 'evts_3',\n",
       "       'expandEvts_3', 'pruneBacktrackEvts_3', 'backtrackEvts_3',\n",
       "       'strengthenEvts_3', 'maxStackDepth_3', 'censored', 'final_expandEvts',\n",
       "       'final_maxStackDepth', 'stop_iter', 'avg_evts', 'max_evts',\n",
       "       'avg_expandEvts', 'max_expandEvts', 'avg_pruneBacktrackEvts',\n",
       "       'max_pruneBacktrackEvts', 'evts_4', 'expandEvts_4',\n",
       "       'pruneBacktrackEvts_4', 'backtrackEvts_4', 'strengthenEvts_4',\n",
       "       'maxStackDepth_4', 'evts_5', 'expandEvts_5', 'pruneBacktrackEvts_5',\n",
       "       'backtrackEvts_5', 'strengthenEvts_5', 'maxStackDepth_5', 'n', 'k',\n",
       "       'total_sum', 'variance', 'skewness', 'max_num', 'min_num',\n",
       "       'avg_subset_sum', 'max_to_avg_ratio', 'range_to_avg_ratio',\n",
       "       'coef_of_variation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65047797-f623-4cea-a69f-4b44d6433bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('structured_data.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-manipulation-class",
   "language": "python",
   "name": "data-manipulation-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
