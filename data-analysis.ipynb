{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ac526d-81a4-4ce9-9082-121a8202f5de",
   "metadata": {},
   "source": [
    "# Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d943dd-1f78-49ba-8b57-21976aa1cc2f",
   "metadata": {},
   "source": [
    "## Objective: \n",
    "Create a pipeline to transform the log data into a dataframe we can use for predictive modelling.\n",
    "\n",
    "## Table format: Features\n",
    "\n",
    "### Input Features\n",
    "\n",
    "- $ n $: Number of elements (e.g., 16, 31).\n",
    "- $ k $: Number of partitions (e.g., 5, 4).\n",
    "- Total sum: $ \\sum S $ (requires input numbers).\n",
    "- Variance: $ \\text{var}(S) $.\n",
    "- Skewness: Distribution shape\n",
    "- Max/min number.\n",
    "- Average subset sum: $ \\text{total sum} / k $.\n",
    "\n",
    "### Solver Features (First $ k $ Logs at stackDepth=3):\n",
    "\n",
    "**For each log (up to $ k $):**\n",
    "\n",
    "- evts: Events at stackDepth=3.\n",
    "- expandEvts: Expansions.\n",
    "- pruneBacktrackEvts: Pruning backtracks.\n",
    "- backtrackEvts: Non-pruning backtracks.\n",
    "- strengthenEvts: Constraint tightenings.\n",
    "- maxStackDepth: Maximum depth reached.\n",
    "- Subset sums: Sum of numbers assigned to each subset based on path (requires input numbers).\n",
    "- Subset sum variance: Variance of subset sums.\n",
    "- Aggregated: Average or max evts, expandEvts, pruneBacktrackEvts across the $ k $ logs.\n",
    "- num_stackdepth3_logs: Number of stackDepth=3 logs (proxy for search difficulty).\n",
    "\n",
    "### Termination/Timeout Features\n",
    "- expandEvts (target variable).\n",
    "- Censored flag: 1 for timeouts, 0 for completions.\n",
    "- Objective value: maxsum - minsum (if available, e.g., 2 for $ n=10, k=3 $)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4147a1e7-32ff-4a08-8344-b1b56a408eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ab28a-c06c-4ddc-b433-f0edbfdd13c6",
   "metadata": {},
   "source": [
    "# 1. Create a dataframe with solver features\n",
    "The solver features are as listed above. The index will be the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59262034-d4ef-465c-b1dc-23d5495289eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 690 instances\n",
      "DataFrame shape: (690, 43)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_ml_features(jsonl_path):\n",
    "    \"\"\"\n",
    "    Extract ML features from the ml_features.jsonl file.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to the ml_features.jsonl file\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the extracted features\n",
    "    \"\"\"\n",
    "    # List to store data for each instance\n",
    "    data_list = []\n",
    "    \n",
    "    # Open and process the JSONL file\n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Parse the JSON line\n",
    "                line_data = json.loads(line.strip())\n",
    "                \n",
    "                # Each line contains a single key (filename) with an array of log entries\n",
    "                for filename, logs in line_data.items():\n",
    "                    if not logs:  # Skip if no logs\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract n and k from filename using regex\n",
    "                    match = re.search(r'n(\\d+)k(\\d+)', filename)\n",
    "                    if match:\n",
    "                        n = int(match.group(1))  # Number of values\n",
    "                        k = int(match.group(2))  # Number of partitions\n",
    "                    else:\n",
    "                        # If pattern doesn't match, try to infer from the logs\n",
    "                        k = max(3, min(5, len(logs)))\n",
    "                        n = 0  # Unknown\n",
    "                    \n",
    "                    # Initialize feature dictionary\n",
    "                    features = {\n",
    "                        'filename': filename,\n",
    "                        'n': n,\n",
    "                        'k': k,\n",
    "                        'num_stackdepth3_logs': 0\n",
    "                    }\n",
    "                    \n",
    "                    # Extract individual log features (up to k logs)\n",
    "                    for i in range(min(k, len(logs))):\n",
    "                        log = logs[i]\n",
    "                        \n",
    "                        if log.get('stackDepth', 0) == 3:\n",
    "                            features['num_stackdepth3_logs'] += 1\n",
    "                            \n",
    "                        # Extract all numeric features from this log\n",
    "                        for field in ['evts', 'expandEvts', 'pruneBacktrackEvts', \n",
    "                                     'backtrackEvts', 'strengthenEvts', 'maxStackDepth']:\n",
    "                            if field in log:\n",
    "                                features[f'{field}_{i+1}'] = log[field]\n",
    "                    \n",
    "                    # Find the termination or timeout event (should be the last log)\n",
    "                    last_log = logs[-1]\n",
    "                    last_event = last_log.get('event', '')\n",
    "                    \n",
    "                    # Check for either TIMEOUT or TERMINATE events\n",
    "                    is_timeout = last_event == 'TIMEOUT'\n",
    "                    is_terminated = last_event == 'TERMINATE'\n",
    "                    \n",
    "                    # Add target variables\n",
    "                    features['censored'] = 1 if is_timeout else 0\n",
    "                    features['final_expandEvts'] = last_log.get('expandEvts', 0)\n",
    "                    features['final_maxStackDepth'] = last_log.get('maxStackDepth', 0)\n",
    "                    \n",
    "                    # Add specific event information if available\n",
    "                    if is_timeout and 'timeoutAt' in last_log:\n",
    "                        features['stop_iter'] = last_log['timeoutAt']\n",
    "                    elif is_terminated and 'terminateAt' in last_log:\n",
    "                        features['stop_iter'] = last_log['terminateAt']\n",
    "                    else:\n",
    "                        features['stop_iter'] = last_log.get('iter', 0)\n",
    "                    \n",
    "                    # Calculate aggregated features\n",
    "                    for field in ['evts', 'expandEvts', 'pruneBacktrackEvts']:\n",
    "                        values = [log.get(field, 0) for log in logs[:k] if field in log]\n",
    "                        if values:\n",
    "                            features[f'avg_{field}'] = sum(values) / len(values)\n",
    "                            features[f'max_{field}'] = max(values)\n",
    "                    \n",
    "                    # Add to data list\n",
    "                    data_list.append(features)\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON line: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.set_index(\"filename\")\n",
    "    \n",
    "    # For demonstration, print the shape and first few rows\n",
    "    print(f\"Extracted features for {len(df)} instances\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "solver_features_df = extract_ml_features(\"ml_features.jsonl\")\n",
    "# df.to_csv(\"ml_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d33b8f-50c2-493a-be73-dc5239756cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>num_stackdepth3_logs</th>\n",
       "      <th>evts_1</th>\n",
       "      <th>expandEvts_1</th>\n",
       "      <th>pruneBacktrackEvts_1</th>\n",
       "      <th>backtrackEvts_1</th>\n",
       "      <th>strengthenEvts_1</th>\n",
       "      <th>maxStackDepth_1</th>\n",
       "      <th>evts_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pruneBacktrackEvts_4</th>\n",
       "      <th>backtrackEvts_4</th>\n",
       "      <th>strengthenEvts_4</th>\n",
       "      <th>maxStackDepth_4</th>\n",
       "      <th>evts_5</th>\n",
       "      <th>expandEvts_5</th>\n",
       "      <th>pruneBacktrackEvts_5</th>\n",
       "      <th>backtrackEvts_5</th>\n",
       "      <th>strengthenEvts_5</th>\n",
       "      <th>maxStackDepth_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               n  k  num_stackdepth3_logs  evts_1  expandEvts_1  \\\n",
       "filename                                                          \n",
       "n10k3_v1.txt  10  3                     3       4             4   \n",
       "n10k3_v2.txt  10  3                     3       4             4   \n",
       "n10k3_v3.txt  10  3                     3       4             4   \n",
       "n10k3_v4.txt  10  3                     3       4             4   \n",
       "n10k3_v5.txt  10  3                     3       4             4   \n",
       "...           .. ..                   ...     ...           ...   \n",
       "n9k5_v1.txt    9  5                     2       4             4   \n",
       "n9k5_v2.txt    9  5                     5       4             4   \n",
       "n9k5_v3.txt    9  5                     2       4             4   \n",
       "n9k5_v4.txt    9  5                     2       4             4   \n",
       "n9k5_v5.txt    9  5                     5       4             4   \n",
       "\n",
       "              pruneBacktrackEvts_1  backtrackEvts_1  strengthenEvts_1  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt                     0                0                 0   \n",
       "n10k3_v2.txt                     0                0                 0   \n",
       "n10k3_v3.txt                     0                0                 0   \n",
       "n10k3_v4.txt                     0                0                 0   \n",
       "n10k3_v5.txt                     0                0                 0   \n",
       "...                            ...              ...               ...   \n",
       "n9k5_v1.txt                      0                0                 0   \n",
       "n9k5_v2.txt                      0                0                 0   \n",
       "n9k5_v3.txt                      0                0                 0   \n",
       "n9k5_v4.txt                      0                0                 0   \n",
       "n9k5_v5.txt                      0                0                 0   \n",
       "\n",
       "              maxStackDepth_1  evts_2  ...  pruneBacktrackEvts_4  \\\n",
       "filename                               ...                         \n",
       "n10k3_v1.txt                3      60  ...                   NaN   \n",
       "n10k3_v2.txt                3      59  ...                   NaN   \n",
       "n10k3_v3.txt                3      66  ...                   NaN   \n",
       "n10k3_v4.txt                3     106  ...                   NaN   \n",
       "n10k3_v5.txt                3      21  ...                   NaN   \n",
       "...                       ...     ...  ...                   ...   \n",
       "n9k5_v1.txt                 3      19  ...                   NaN   \n",
       "n9k5_v2.txt                 3      27  ...                  29.0   \n",
       "n9k5_v3.txt                 3      19  ...                   NaN   \n",
       "n9k5_v4.txt                 3      19  ...                   NaN   \n",
       "n9k5_v5.txt                 3      23  ...                  19.0   \n",
       "\n",
       "              backtrackEvts_4  strengthenEvts_4  maxStackDepth_4  evts_5  \\\n",
       "filename                                                                   \n",
       "n10k3_v1.txt              NaN               NaN              NaN     NaN   \n",
       "n10k3_v2.txt              NaN               NaN              NaN     NaN   \n",
       "n10k3_v3.txt              NaN               NaN              NaN     NaN   \n",
       "n10k3_v4.txt              NaN               NaN              NaN     NaN   \n",
       "n10k3_v5.txt              NaN               NaN              NaN     NaN   \n",
       "...                       ...               ...              ...     ...   \n",
       "n9k5_v1.txt               NaN               NaN              NaN     NaN   \n",
       "n9k5_v2.txt               1.0               1.0             10.0    65.0   \n",
       "n9k5_v3.txt               NaN               NaN              NaN     NaN   \n",
       "n9k5_v4.txt               NaN               NaN              NaN     NaN   \n",
       "n9k5_v5.txt               1.0               1.0             10.0    45.0   \n",
       "\n",
       "              expandEvts_5  pruneBacktrackEvts_5  backtrackEvts_5  \\\n",
       "filename                                                            \n",
       "n10k3_v1.txt           NaN                   NaN              NaN   \n",
       "n10k3_v2.txt           NaN                   NaN              NaN   \n",
       "n10k3_v3.txt           NaN                   NaN              NaN   \n",
       "n10k3_v4.txt           NaN                   NaN              NaN   \n",
       "n10k3_v5.txt           NaN                   NaN              NaN   \n",
       "...                    ...                   ...              ...   \n",
       "n9k5_v1.txt            NaN                   NaN              NaN   \n",
       "n9k5_v2.txt           34.0                  29.0              1.0   \n",
       "n9k5_v3.txt            NaN                   NaN              NaN   \n",
       "n9k5_v4.txt            NaN                   NaN              NaN   \n",
       "n9k5_v5.txt           24.0                  19.0              1.0   \n",
       "\n",
       "              strengthenEvts_5  maxStackDepth_5  \n",
       "filename                                         \n",
       "n10k3_v1.txt               NaN              NaN  \n",
       "n10k3_v2.txt               NaN              NaN  \n",
       "n10k3_v3.txt               NaN              NaN  \n",
       "n10k3_v4.txt               NaN              NaN  \n",
       "n10k3_v5.txt               NaN              NaN  \n",
       "...                        ...              ...  \n",
       "n9k5_v1.txt                NaN              NaN  \n",
       "n9k5_v2.txt                1.0             10.0  \n",
       "n9k5_v3.txt                NaN              NaN  \n",
       "n9k5_v4.txt                NaN              NaN  \n",
       "n9k5_v5.txt                1.0             10.0  \n",
       "\n",
       "[690 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a375aa-262a-49c2-a4b3-8e57d0a0b8bd",
   "metadata": {},
   "source": [
    "## 2. Create a Dataframe with input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da3d811-5a73-49cd-8ae3-735cc02397d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 520 instance files\n",
      "Missing 170 files\n",
      "First few missing files: ['n10k3_v1.txt', 'n10k3_v2.txt', 'n10k3_v3.txt', 'n10k3_v4.txt', 'n10k3_v5.txt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "      <th>total_sum</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>max_num</th>\n",
       "      <th>min_num</th>\n",
       "      <th>avg_subset_sum</th>\n",
       "      <th>perfect_partition_sum</th>\n",
       "      <th>max_to_avg_ratio</th>\n",
       "      <th>range_to_avg_ratio</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1161.654321</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1.069042</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.683179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>580.024691</td>\n",
       "      <td>-0.392412</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>105.4</td>\n",
       "      <td>105.4</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.702087</td>\n",
       "      <td>0.411297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1034.469136</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>90.8</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>1.046256</td>\n",
       "      <td>0.637596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>938.691358</td>\n",
       "      <td>0.280482</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>76.6</td>\n",
       "      <td>1.187990</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>0.719955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>940.543210</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1.013363</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.614732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                n    k  total_sum     variance  skewness  max_num  min_num  \\\n",
       "filename                                                                     \n",
       "n10k3_v1.txt  NaN  NaN        NaN          NaN       NaN      NaN      NaN   \n",
       "n10k3_v2.txt  NaN  NaN        NaN          NaN       NaN      NaN      NaN   \n",
       "n10k3_v3.txt  NaN  NaN        NaN          NaN       NaN      NaN      NaN   \n",
       "n10k3_v4.txt  NaN  NaN        NaN          NaN       NaN      NaN      NaN   \n",
       "n10k3_v5.txt  NaN  NaN        NaN          NaN       NaN      NaN      NaN   \n",
       "...           ...  ...        ...          ...       ...      ...      ...   \n",
       "n9k5_v1.txt   9.0  5.0      449.0  1161.654321  0.116110     96.0      8.0   \n",
       "n9k5_v2.txt   9.0  5.0      527.0   580.024691 -0.392412     86.0     12.0   \n",
       "n9k5_v3.txt   9.0  5.0      454.0  1034.469136  0.112580     98.0      3.0   \n",
       "n9k5_v4.txt   9.0  5.0      383.0   938.691358  0.280482     91.0      3.0   \n",
       "n9k5_v5.txt   9.0  5.0      449.0   940.543210 -0.003903     91.0      5.0   \n",
       "\n",
       "              avg_subset_sum  perfect_partition_sum  max_to_avg_ratio  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt             NaN                    NaN               NaN   \n",
       "n10k3_v2.txt             NaN                    NaN               NaN   \n",
       "n10k3_v3.txt             NaN                    NaN               NaN   \n",
       "n10k3_v4.txt             NaN                    NaN               NaN   \n",
       "n10k3_v5.txt             NaN                    NaN               NaN   \n",
       "...                      ...                    ...               ...   \n",
       "n9k5_v1.txt             89.8                   89.8          1.069042   \n",
       "n9k5_v2.txt            105.4                  105.4          0.815939   \n",
       "n9k5_v3.txt             90.8                   90.8          1.079295   \n",
       "n9k5_v4.txt             76.6                   76.6          1.187990   \n",
       "n9k5_v5.txt             89.8                   89.8          1.013363   \n",
       "\n",
       "              range_to_avg_ratio  coef_of_variation  \n",
       "filename                                             \n",
       "n10k3_v1.txt                 NaN                NaN  \n",
       "n10k3_v2.txt                 NaN                NaN  \n",
       "n10k3_v3.txt                 NaN                NaN  \n",
       "n10k3_v4.txt                 NaN                NaN  \n",
       "n10k3_v5.txt                 NaN                NaN  \n",
       "...                          ...                ...  \n",
       "n9k5_v1.txt             0.979955           0.683179  \n",
       "n9k5_v2.txt             0.702087           0.411297  \n",
       "n9k5_v3.txt             1.046256           0.637596  \n",
       "n9k5_v4.txt             1.148825           0.719955  \n",
       "n9k5_v5.txt             0.957684           0.614732  \n",
       "\n",
       "[690 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def process_path_features(df, instance_dir):\n",
    "    \"\"\"\n",
    "    Process input features from the original instance files.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with existing features from logs\n",
    "        instance_dir: Directory containing the original instance files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with input features\n",
    "    \"\"\"\n",
    "    # Create a new DataFrame for input features with filename as index\n",
    "    input_features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Track missing files\n",
    "    missing_files = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    # Process each file\n",
    "    for filename in df.index:\n",
    "        file_path = os.path.join(instance_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                missing_files.append(filename)\n",
    "                continue\n",
    "                \n",
    "            # Read the instance file\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Extract data from file\n",
    "            solution = int(lines[0].strip())  # -1 if no solution\n",
    "            k = int(lines[1].strip())         # number of partitions\n",
    "            numbers = [int(line.strip()) for line in lines[2:]]\n",
    "            n = len(numbers)                  # number of elements\n",
    "            \n",
    "            # Calculate basic input features\n",
    "            total_sum = sum(numbers)\n",
    "            variance = np.var(numbers) if n > 1 else 0\n",
    "            skewness = stats.skew(numbers) if n > 2 else 0\n",
    "            max_num = max(numbers) if numbers else 0\n",
    "            min_num = min(numbers) if numbers else 0\n",
    "            avg_subset_sum = total_sum / k if k > 0 else 0\n",
    "            \n",
    "            # Store features\n",
    "            input_features.loc[filename, 'n'] = n\n",
    "            input_features.loc[filename, 'k'] = k\n",
    "            input_features.loc[filename, 'total_sum'] = total_sum\n",
    "            input_features.loc[filename, 'variance'] = variance\n",
    "            input_features.loc[filename, 'skewness'] = skewness\n",
    "            input_features.loc[filename, 'max_num'] = max_num\n",
    "            input_features.loc[filename, 'min_num'] = min_num\n",
    "            input_features.loc[filename, 'avg_subset_sum'] = avg_subset_sum\n",
    "            # input_features.loc[filename, 'solution_exists'] = 0 if solution == -1 else 1\n",
    "            \n",
    "            # Calculate additional features\n",
    "            # Theoretical minimum objective value (difference between max and min subset sums)\n",
    "            # In perfect partitioning, all subsets would have the same sum\n",
    "            perfect_partition = total_sum / k\n",
    "            input_features.loc[filename, 'perfect_partition_sum'] = perfect_partition\n",
    "            \n",
    "            # How close is the maximum number to the average subset sum?\n",
    "            # If max_num > avg_subset_sum, the problem is likely harder\n",
    "            input_features.loc[filename, 'max_to_avg_ratio'] = max_num / avg_subset_sum if avg_subset_sum > 0 else float('inf')\n",
    "            \n",
    "            # Range to average ratio\n",
    "            input_features.loc[filename, 'range_to_avg_ratio'] = (max_num - min_num) / avg_subset_sum if avg_subset_sum > 0 else float('inf')\n",
    "            \n",
    "            # Coefficient of variation (standardized measure of dispersion)\n",
    "            mean = np.mean(numbers)\n",
    "            std_dev = np.std(numbers)\n",
    "            input_features.loc[filename, 'coef_of_variation'] = std_dev / mean if mean > 0 else 0\n",
    "            \n",
    "            processed_files += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            missing_files.append(filename)\n",
    "    \n",
    "    print(f\"Processed {processed_files} instance files\")\n",
    "    print(f\"Missing {len(missing_files)} files\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"First few missing files: {missing_files[:5]}\")\n",
    "    \n",
    "    # Return a new DataFrame with input features\n",
    "    # This keeps the original df unchanged and allows for better merging later\n",
    "    return input_features\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "instance_dir = \"solver/numpart/instances/feature_collected\"\n",
    "input_features_df = process_path_features(solver_features_df, instance_dir)\n",
    "# df = extract_and_analyze_ml_features(\"ml_features.jsonl\", instance_dir)\n",
    "# df.to_csv(\"ml_features_complete.csv\", index=False)\n",
    "\n",
    "input_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25aefbb-ba77-479c-b83e-ea4ed05175f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged features: 690 rows, 55 columns\n"
     ]
    }
   ],
   "source": [
    "def merge_features(solver_features_df, input_features_df):\n",
    "    \"\"\"\n",
    "    Merge solver features with input features.\n",
    "    \n",
    "    Args:\n",
    "        solver_features_df: DataFrame with solver features\n",
    "        input_features_df: DataFrame with input features\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Merged DataFrame\n",
    "    \"\"\"\n",
    "    # Set filename as index for solver features to enable proper joining\n",
    "    # solver_features_df = solver_features_df.set_index('filename')\n",
    "    \n",
    "    # Merge DataFrames on filename index\n",
    "    merged_df = solver_features_df.join(input_features_df, how='inner', lsuffix='_solver', rsuffix='_input')\n",
    "    \n",
    "    # Reset index to make filename a column again\n",
    "    # merged_df = merged_df.reset_index()\n",
    "    \n",
    "    print(f\"Merged features: {len(merged_df)} rows, {len(merged_df.columns)} columns\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "df = merge_features(solver_features_df, input_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e69d27-cb74-4100-a50e-741b63de22f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_solver</th>\n",
       "      <th>k_solver</th>\n",
       "      <th>num_stackdepth3_logs</th>\n",
       "      <th>evts_1</th>\n",
       "      <th>expandEvts_1</th>\n",
       "      <th>pruneBacktrackEvts_1</th>\n",
       "      <th>backtrackEvts_1</th>\n",
       "      <th>strengthenEvts_1</th>\n",
       "      <th>maxStackDepth_1</th>\n",
       "      <th>evts_2</th>\n",
       "      <th>...</th>\n",
       "      <th>total_sum</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>max_num</th>\n",
       "      <th>min_num</th>\n",
       "      <th>avg_subset_sum</th>\n",
       "      <th>perfect_partition_sum</th>\n",
       "      <th>max_to_avg_ratio</th>\n",
       "      <th>range_to_avg_ratio</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n10k3_v1.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v2.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v3.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v4.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n10k3_v5.txt</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v1.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1161.654321</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1.069042</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.683179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v2.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>527.0</td>\n",
       "      <td>580.024691</td>\n",
       "      <td>-0.392412</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>105.4</td>\n",
       "      <td>105.4</td>\n",
       "      <td>0.815939</td>\n",
       "      <td>0.702087</td>\n",
       "      <td>0.411297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v3.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>454.0</td>\n",
       "      <td>1034.469136</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>90.8</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>1.046256</td>\n",
       "      <td>0.637596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v4.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>383.0</td>\n",
       "      <td>938.691358</td>\n",
       "      <td>0.280482</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>76.6</td>\n",
       "      <td>1.187990</td>\n",
       "      <td>1.148825</td>\n",
       "      <td>0.719955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n9k5_v5.txt</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>449.0</td>\n",
       "      <td>940.543210</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>1.013363</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.614732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n_solver  k_solver  num_stackdepth3_logs  evts_1  expandEvts_1  \\\n",
       "filename                                                                       \n",
       "n10k3_v1.txt        10         3                     3       4             4   \n",
       "n10k3_v2.txt        10         3                     3       4             4   \n",
       "n10k3_v3.txt        10         3                     3       4             4   \n",
       "n10k3_v4.txt        10         3                     3       4             4   \n",
       "n10k3_v5.txt        10         3                     3       4             4   \n",
       "...                ...       ...                   ...     ...           ...   \n",
       "n9k5_v1.txt          9         5                     2       4             4   \n",
       "n9k5_v2.txt          9         5                     5       4             4   \n",
       "n9k5_v3.txt          9         5                     2       4             4   \n",
       "n9k5_v4.txt          9         5                     2       4             4   \n",
       "n9k5_v5.txt          9         5                     5       4             4   \n",
       "\n",
       "              pruneBacktrackEvts_1  backtrackEvts_1  strengthenEvts_1  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt                     0                0                 0   \n",
       "n10k3_v2.txt                     0                0                 0   \n",
       "n10k3_v3.txt                     0                0                 0   \n",
       "n10k3_v4.txt                     0                0                 0   \n",
       "n10k3_v5.txt                     0                0                 0   \n",
       "...                            ...              ...               ...   \n",
       "n9k5_v1.txt                      0                0                 0   \n",
       "n9k5_v2.txt                      0                0                 0   \n",
       "n9k5_v3.txt                      0                0                 0   \n",
       "n9k5_v4.txt                      0                0                 0   \n",
       "n9k5_v5.txt                      0                0                 0   \n",
       "\n",
       "              maxStackDepth_1  evts_2  ...  total_sum     variance  skewness  \\\n",
       "filename                               ...                                     \n",
       "n10k3_v1.txt                3      60  ...        NaN          NaN       NaN   \n",
       "n10k3_v2.txt                3      59  ...        NaN          NaN       NaN   \n",
       "n10k3_v3.txt                3      66  ...        NaN          NaN       NaN   \n",
       "n10k3_v4.txt                3     106  ...        NaN          NaN       NaN   \n",
       "n10k3_v5.txt                3      21  ...        NaN          NaN       NaN   \n",
       "...                       ...     ...  ...        ...          ...       ...   \n",
       "n9k5_v1.txt                 3      19  ...      449.0  1161.654321  0.116110   \n",
       "n9k5_v2.txt                 3      27  ...      527.0   580.024691 -0.392412   \n",
       "n9k5_v3.txt                 3      19  ...      454.0  1034.469136  0.112580   \n",
       "n9k5_v4.txt                 3      19  ...      383.0   938.691358  0.280482   \n",
       "n9k5_v5.txt                 3      23  ...      449.0   940.543210 -0.003903   \n",
       "\n",
       "              max_num  min_num  avg_subset_sum  perfect_partition_sum  \\\n",
       "filename                                                                \n",
       "n10k3_v1.txt      NaN      NaN             NaN                    NaN   \n",
       "n10k3_v2.txt      NaN      NaN             NaN                    NaN   \n",
       "n10k3_v3.txt      NaN      NaN             NaN                    NaN   \n",
       "n10k3_v4.txt      NaN      NaN             NaN                    NaN   \n",
       "n10k3_v5.txt      NaN      NaN             NaN                    NaN   \n",
       "...               ...      ...             ...                    ...   \n",
       "n9k5_v1.txt      96.0      8.0            89.8                   89.8   \n",
       "n9k5_v2.txt      86.0     12.0           105.4                  105.4   \n",
       "n9k5_v3.txt      98.0      3.0            90.8                   90.8   \n",
       "n9k5_v4.txt      91.0      3.0            76.6                   76.6   \n",
       "n9k5_v5.txt      91.0      5.0            89.8                   89.8   \n",
       "\n",
       "              max_to_avg_ratio  range_to_avg_ratio  coef_of_variation  \n",
       "filename                                                               \n",
       "n10k3_v1.txt               NaN                 NaN                NaN  \n",
       "n10k3_v2.txt               NaN                 NaN                NaN  \n",
       "n10k3_v3.txt               NaN                 NaN                NaN  \n",
       "n10k3_v4.txt               NaN                 NaN                NaN  \n",
       "n10k3_v5.txt               NaN                 NaN                NaN  \n",
       "...                        ...                 ...                ...  \n",
       "n9k5_v1.txt           1.069042            0.979955           0.683179  \n",
       "n9k5_v2.txt           0.815939            0.702087           0.411297  \n",
       "n9k5_v3.txt           1.079295            1.046256           0.637596  \n",
       "n9k5_v4.txt           1.187990            1.148825           0.719955  \n",
       "n9k5_v5.txt           1.013363            0.957684           0.614732  \n",
       "\n",
       "[690 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61cf320e-7b76-4f55-9f73-5f82595d7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features(df):\n",
    "    \"\"\"\n",
    "    Perform basic analysis on the extracted features.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with extracted features\n",
    "        \n",
    "    Returns:\n",
    "        dict: Basic statistics about the features\n",
    "    \"\"\"\n",
    "    stats_dict = {\n",
    "        'total_instances': len(df),\n",
    "        'timeout_instances': df['censored'].sum() if 'censored' in df.columns else 'N/A',\n",
    "        'complete_instances': (len(df) - df['censored'].sum()) if 'censored' in df.columns else 'N/A',\n",
    "    }\n",
    "    \n",
    "    # Add statistics for key numeric columns\n",
    "    numeric_cols = ['final_expandEvts', 'final_maxStackDepth', 'total_sum', 'variance', \n",
    "                    'max_num', 'avg_subset_sum'] \n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            stats_dict[f'avg_{col}'] = df[col].mean()\n",
    "            stats_dict[f'max_{col}'] = df[col].max()\n",
    "    \n",
    "    print(\"\\nFeature Statistics:\")\n",
    "    for key, value in stats_dict.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "def extract_and_analyze_ml_features(jsonl_path, instance_dir):\n",
    "    \"\"\"\n",
    "    Main function to extract and analyze ML features.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to the ml_features.jsonl file\n",
    "        instance_dir: Directory containing original instance files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with extracted features\n",
    "    \"\"\"\n",
    "    print(f\"Processing {jsonl_path}...\")\n",
    "    \n",
    "    # Extract solver features\n",
    "    solver_features_df = extract_ml_features(jsonl_path)\n",
    "    \n",
    "    # Extract input features\n",
    "    print(f\"\\nProcessing instance files from {instance_dir}...\")\n",
    "    input_features_df = process_path_features(solver_features_df, instance_dir)\n",
    "    \n",
    "    # Merge features\n",
    "    merged_df = merge_features(solver_features_df, input_features_df)\n",
    "    \n",
    "    # Analyze features\n",
    "    analyze_features(merged_df)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de59553-1893-498e-9b26-9891b5cee84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_analyze_ml_features(jsonl_path, instance_dir=None):\n",
    "    \"\"\"\n",
    "    Main function to extract and analyze ML features.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path: Path to the ml_features.jsonl file\n",
    "        instance_dir: Optional directory containing original instance files\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with extracted features\n",
    "    \"\"\"\n",
    "    print(f\"Processing {jsonl_path}...\")\n",
    "    \n",
    "    # Extract basic features\n",
    "    df = extract_ml_features(jsonl_path)\n",
    "    \n",
    "    # Process path-based features if instance directory is provided\n",
    "    if instance_dir:\n",
    "        df = process_path_features(df, instance_dir)\n",
    "    \n",
    "    # Analyze features\n",
    "    analyze_features(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b10853d-b10e-494b-ae6b-4f239bdd8347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n_solver', 'k_solver', 'num_stackdepth3_logs', 'evts_1',\n",
       "       'expandEvts_1', 'pruneBacktrackEvts_1', 'backtrackEvts_1',\n",
       "       'strengthenEvts_1', 'maxStackDepth_1', 'evts_2', 'expandEvts_2',\n",
       "       'pruneBacktrackEvts_2', 'backtrackEvts_2', 'strengthenEvts_2',\n",
       "       'maxStackDepth_2', 'evts_3', 'expandEvts_3', 'pruneBacktrackEvts_3',\n",
       "       'backtrackEvts_3', 'strengthenEvts_3', 'maxStackDepth_3', 'censored',\n",
       "       'final_expandEvts', 'final_maxStackDepth', 'stop_iter', 'avg_evts',\n",
       "       'max_evts', 'avg_expandEvts', 'max_expandEvts',\n",
       "       'avg_pruneBacktrackEvts', 'max_pruneBacktrackEvts', 'evts_4',\n",
       "       'expandEvts_4', 'pruneBacktrackEvts_4', 'backtrackEvts_4',\n",
       "       'strengthenEvts_4', 'maxStackDepth_4', 'evts_5', 'expandEvts_5',\n",
       "       'pruneBacktrackEvts_5', 'backtrackEvts_5', 'strengthenEvts_5',\n",
       "       'maxStackDepth_5', 'n_input', 'k_input', 'total_sum', 'variance',\n",
       "       'skewness', 'max_num', 'min_num', 'avg_subset_sum',\n",
       "       'perfect_partition_sum', 'max_to_avg_ratio', 'range_to_avg_ratio',\n",
       "       'coef_of_variation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65047797-f623-4cea-a69f-4b44d6433bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('structured_data.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-manipulation-class",
   "language": "python",
   "name": "data-manipulation-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
